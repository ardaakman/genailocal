{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[105, 26], [323, 26], [323, 65], [105, 65]], 'Messages File'],\n",
       " [[[357, 26], [413, 26], [413, 56], [357, 56]], 'Edit'],\n",
       " [[[450, 30], [512, 30], [512, 56], [450, 56]], 'View'],\n",
       " [[[550, 30], [715, 30], [715, 59], [550, 59]], 'Conversation'],\n",
       " [[[749, 30], [853, 30], [853, 56], [749, 56]], 'Window'],\n",
       " [[[884, 26], [946, 26], [946, 59], [884, 59]], 'Help'],\n",
       " [[[2454, 25], [2797, 25], [2797, 61], [2454, 61]],\n",
       "  'Al Goes Local . 2h 49m left'],\n",
       " [[[2965, 22], [3240, 22], [3240, 67], [2965, 67]], '@ # @s) 0'],\n",
       " [[[3344, 25], [3684, 25], [3684, 62], [3344, 62]],\n",
       "  'Al Goes Local (2h 49m left)'],\n",
       " [[[3843, 26], [4081, 26], [4081, 59], [3843, 59]], 'Sat Sep 5:11PM'],\n",
       " [[[681, 122], [963, 122], [963, 160], [681, 160]], 'To: +1 (510) 542-0847'],\n",
       " [[[71, 206], [165, 206], [165, 239], [71, 239]], 'Search'],\n",
       " [[[2319, 218], [2437, 218], [2437, 250], [2319, 250]], 'iMessage'],\n",
       " [[[2247, 241], [2508, 241], [2508, 277], [2247, 277]],\n",
       "  'Tue, Jul 23 at 2:57PM'],\n",
       " [[[142, 283], [602, 283], [602, 381], [142, 381]],\n",
       "  '+1 (510) 542-0847 3:50 PM Website: Launch YC: papl _ Automatic refunds for consumers (ycombinator:c_.'],\n",
       " [[[3302, 332], [4085, 332], [4085, 422], [3302, 422]],\n",
       "  \"Kamal congrats on YC dudel Hope you're doing good Delivered\"],\n",
       " [[[145, 415], [602, 415], [602, 512], [145, 512]],\n",
       "  'europe 3.03 PM +1 (412) 680-5544 laughed at \"Matt double boozing\"'],\n",
       " [[[2288, 454], [2465, 454], [2465, 487], [2288, 487]], 'Today 3:50PM'],\n",
       " [[[684, 511], [990, 511], [990, 677], [684, 677]],\n",
       "  'Thank you Mehmet Sorry for missing this Just launched :)'],\n",
       " [[[141, 543], [603, 543], [603, 645], [141, 645]],\n",
       "  '+1 (510) 467-2510 12*27 PM Website: 9/7 GenAI Goes Local Hackathon Lightning Proposals (docs.g_'],\n",
       " [[[145, 669], [602, 669], [602, 773], [145, 773]],\n",
       "  '+1 (404) 277-7816 11.36 AM btw we re meeting up at pacific heights at 6pm W raj and larissa youre down'],\n",
       " [[[686, 699], [759, 699], [759, 739], [686, 739]], 'papl'],\n",
       " [[[696, 779], [987, 779], [987, 942], [696, 942]],\n",
       "  'Sign up once_ Forget we exist: Earn money:'],\n",
       " [[[1136, 786], [1183, 786], [1183, 807], [1136, 807]], 'papl'],\n",
       " [[[144, 803], [602, 803], [602, 904], [144, 904]],\n",
       "  '+1 (914) 582-1726 11.34 AM can do 11:30am or 3pm your time? Are you free around then? Do you have a cl:'],\n",
       " [[[1071, 840], [1131, 840], [1131, 852], [1071, 852]], 'we\"ve done'],\n",
       " [[[1171, 840], [1244, 840], [1244, 852], [1171, 852]], 'refund alert !'],\n",
       " [[[1048, 865], [1270, 865], [1270, 926], [1048, 926]], '+5120.0'],\n",
       " [[[142, 935], [602, 935], [602, 1004], [142, 1004]],\n",
       "  '+1 (650) 422-1187 10:51AM Build month let me know thoughtsll!'],\n",
       " [[[691, 1051], [1274, 1051], [1274, 1110], [691, 1110]],\n",
       "  'Launch YC: papl  Automatic refunds for consumers ycombinatorcom'],\n",
       " [[[145, 1066], [602, 1066], [602, 1166], [145, 1166]],\n",
       "  \"+1 (720) 526-8777 8.55 AM Can u ask Winston if he's free? sent him the partiful invite but he never rsvpd\"],\n",
       " [[[142, 1198], [607, 1198], [607, 1293], [142, 1293]],\n",
       "  '+1 (847) 917-7439 Yesterday Hahahahha the shit U must have in that basement dude'],\n",
       " [[[141, 1330], [607, 1330], [607, 1396], [141, 1396]],\n",
       "  'arya grayeli@gmail com Yesterday Perrfect'],\n",
       " [[[144, 1458], [391, 1458], [391, 1530], [144, 1530]],\n",
       "  '+1 (305) 972-1428 Attachment: Image'],\n",
       " [[[484, 1461], [607, 1461], [607, 1497], [484, 1497]], 'Yesterday'],\n",
       " [[[145, 1591], [252, 1591], [252, 1656], [145, 1656]], 'Winnie Go for itt'],\n",
       " [[[484, 1593], [607, 1593], [607, 1629], [484, 1629]], 'Yesterday'],\n",
       " [[[145, 1722], [454, 1722], [454, 1791], [145, 1791]],\n",
       "  '+1 (470) 298-4575 How is the vibe going my g'],\n",
       " [[[486, 1729], [605, 1729], [605, 1756], [486, 1756]], 'Yesterday'],\n",
       " [[[145, 1854], [432, 1854], [432, 1919], [145, 1919]],\n",
       "  '+1 (970) 708-7556 Started Sharing Location'],\n",
       " [[[491, 1857], [606, 1857], [606, 1890], [491, 1890]], 'Thursday'],\n",
       " [[[145, 1982], [606, 1982], [606, 2051], [145, 2051]],\n",
       "  '+1 (510) 248-9606 Thursday woudl love to have ya there'],\n",
       " [[[147, 2114], [606, 2114], [606, 2185], [147, 2185]],\n",
       "  '+1 (412) 436-6830 Thursday +1 (412) 436-6830 liked an image'],\n",
       " [[[144, 2245], [426, 2245], [426, 2315], [144, 2315]],\n",
       "  '+1 (786) 459-0662 know him through Eran'],\n",
       " [[[490, 2248], [607, 2248], [607, 2284], [490, 2284]], 'Thursday'],\n",
       " [[[144, 2378], [607, 2378], [607, 2475], [144, 2475]],\n",
       "  \"+1 (862) 485-9128 Thursday What about you? What have you been up to in Amazon AGI? I'm sure you're p_.\"],\n",
       " [[[792, 2402], [929, 2402], [929, 2442], [792, 2442]], 'iMessage'],\n",
       " [[[1083, 2503], [1132, 2503], [1132, 2533], [1083, 2533]], '105'],\n",
       " [[[2795, 2518], [2833, 2518], [2833, 2560], [2795, 2560]], 'sl'],\n",
       " [[[1877, 2542], [1964, 2542], [1964, 2575], [1877, 2575]], 'zoom'],\n",
       " [[[2042, 2540], [2098, 2540], [2098, 2599], [2042, 2599]], 'N']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = reader.readtext(\"images/convo.png\",paragraph=\"True\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdbirlikci/Documents/Code Projects/genailocal/venv/lib/python3.11/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/Users/mdbirlikci/Documents/Code Projects/genailocal/venv/lib/python3.11/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[[129, 0], [504, 0], [504, 15], [129, 15]], 'OCEDDCNCAZ Tius Leaueidoalu'],\n",
       " [[[601, 0], [952, 0], [952, 17], [601, 17]], 'Mi-denC WAL Leauendoaru'],\n",
       " [[[1049, 0], [1281, 0], [1281, 15], [1049, 15]], 'DLIN Leaueidoalu'],\n",
       " [[[1378, 0], [1629, 0], [1629, 20], [1378, 20]], 'Dericn Leauendoaru'],\n",
       " [[[1727, 0], [1975, 0], [1975, 15], [1727, 15]], 'Adencn LeauenDoaru'],\n",
       " [[[2070, 0], [2317, 0], [2317, 17], [2070, 17]], 'MTVQA Leauendoaru'],\n",
       " [[[90, 56], [548, 56], [548, 156], [90, 156]],\n",
       "  'Main Evaluation Results Metrics:'],\n",
       " [[[127, 176], [1800, 176], [1800, 455], [127, 455]],\n",
       "  'Avg = Score: The average score on all VLM Benchmarks (normalized to 0 - 100,the higher the better). Avg Rank: The average rank on all VLM Benchmarks (the lower the better). Avg Score & Rank are calculated based on selected benchmark When results for some selected benchmarks are missing; Avg Score Rank will be Nonelll By default; we present the overall evaluation results based on 8 VLM benchmarks, sorted by the descending order of Avg Score: The following datasets are included in the main results: MMBench_V11, MMStar; MMMU_VAL, MathVista, OCRBench,AIZD, HallusionBench, MMVet: Detailed evaluation results for each dataset (included or not included in main) are provided in the consequent tabs_'],\n",
       " [[[116, 513], [374, 513], [374, 544], [116, 544]], 'Evaluation Dimension'],\n",
       " [[[185, 582], [309, 582], [309, 621], [185, 621]], 'Avg Score'],\n",
       " [[[415, 582], [532, 582], [532, 621], [415, 621]], 'Avg Rank'],\n",
       " [[[644, 586], [817, 586], [817, 614], [644, 614]], 'MMBench_V1I'],\n",
       " [[[929, 586], [1023, 586], [1023, 616], [929, 616]], 'MMStar'],\n",
       " [[[1133, 586], [1192, 586], [1192, 614], [1133, 614]], 'MME'],\n",
       " [[[1304, 586], [1444, 586], [1444, 619], [1304, 619]], 'MMMU_VAL'],\n",
       " [[[1556, 586], [1674, 586], [1674, 614], [1556, 614]], 'MathVista'],\n",
       " [[[1784, 586], [1914, 586], [1914, 614], [1784, 614]], 'OCRBench'],\n",
       " [[[2026, 586], [2083, 586], [2083, 614], [2026, 614]], 'AIZD'],\n",
       " [[[2195, 586], [2386, 586], [2386, 616], [2195, 616]], 'HallusionBench'],\n",
       " [[[2495, 586], [2695, 586], [2695, 614], [2495, 614]], 'SEEDBench_IMG'],\n",
       " [[[2807, 586], [2891, 586], [2891, 614], [2807, 614]], 'MMVet'],\n",
       " [[[189, 670], [338, 670], [338, 701], [189, 701]], 'LLaVABench'],\n",
       " [[[448, 670], [558, 670], [558, 701], [448, 701]], 'CCBench'],\n",
       " [[[670, 670], [827, 670], [827, 703], [670, 703]], 'RealWorldQA'],\n",
       " [[[939, 670], [1011, 670], [1011, 701], [939, 701]], 'POPE'],\n",
       " [[[1118, 670], [1321, 670], [1321, 703], [1118, 703]], 'ScienceQA_TEST'],\n",
       " [[[1433, 670], [1652, 670], [1652, 701], [1433, 701]], 'SEEDBench2_Plus'],\n",
       " [[[1764, 670], [1960, 670], [1960, 701], [1764, 701]], 'MMT-Bench_VAL'],\n",
       " [[[2072, 670], [2148, 670], [2148, 701], [2072, 701]], 'BLINK'],\n",
       " [[[116, 801], [246, 801], [246, 829], [116, 829]], 'Model Size'],\n",
       " [[[1561, 801], [1701, 801], [1701, 834], [1561, 834]], 'Model Type'],\n",
       " [[[189, 874], [239, 874], [239, 902], [189, 902]], '<4B'],\n",
       " [[[348, 871], [440, 871], [440, 902], [348, 902]], '4B-10B'],\n",
       " [[[547, 871], [653, 871], [653, 902], [547, 902]], '10B-20B'],\n",
       " [[[760, 871], [866, 871], [866, 902], [760, 902]], '20B-40B'],\n",
       " [[[973, 874], [1040, 874], [1040, 902], [973, 902]], '>40B'],\n",
       " [[[1150, 871], [1267, 871], [1267, 902], [1150, 902]], 'Unknown'],\n",
       " [[[1634, 871], [1679, 871], [1679, 902], [1634, 902]], 'API'],\n",
       " [[[1789, 871], [1938, 871], [1938, 904], [1789, 904]], 'OpenSource'],\n",
       " [[[2047, 870], [2188, 870], [2188, 908], [2047, 908]], 'Proprietary'],\n",
       " [[[106, 1000], [181, 1000], [181, 1030], [106, 1030]], 'Rank'],\n",
       " [[[261, 997], [367, 997], [367, 1030], [261, 1030]], 'Method'],\n",
       " [[[629, 999], [784, 999], [784, 1036], [629, 1036]], 'Param (B)'],\n",
       " [[[865, 998], [1105, 998], [1105, 1038], [865, 1038]], 'Language Model'],\n",
       " [[[1216, 996], [1424, 996], [1424, 1033], [1216, 1033]], 'Vision Model'],\n",
       " [[[1565, 997], [1726, 997], [1726, 1040], [1565, 1040]], 'Avg Score'],\n",
       " [[[1803, 997], [1945, 997], [1945, 1037], [1803, 1037]], 'Avg Rank'],\n",
       " [[[2023, 1000], [2211, 1000], [2211, 1030], [2023, 1030]], 'MMBench V11'],\n",
       " [[[2292, 1000], [2398, 1000], [2398, 1030], [2292, 1030]], 'MMStar'],\n",
       " [[[2475, 999], [2614, 999], [2614, 1036], [2475, 1036]], 'MMMU_VAL'],\n",
       " [[[2694, 997], [2850, 997], [2850, 1030], [2694, 1030]], 'MathVista'],\n",
       " [[[2928, 1000], [2983, 1000], [2983, 1028], [2928, 1028]], 'OCR'],\n",
       " [[[110, 1078], [126, 1078], [126, 1102], [110, 1102]], '1'],\n",
       " [[[261, 1072], [486, 1072], [486, 1105], [261, 1105]], 'MiniCPM-V-2.6'],\n",
       " [[[864, 1072], [1004, 1072], [1004, 1105], [864, 1105]], 'Qwen2-7B'],\n",
       " [[[1216, 1071], [1409, 1071], [1409, 1109], [1216, 1109]], 'SigLIP-4OOM'],\n",
       " [[[1568, 1072], [1642, 1072], [1642, 1103], [1568, 1103]], '65.2'],\n",
       " [[[1805, 1072], [1897, 1072], [1897, 1105], [1805, 1105]], '13. 62'],\n",
       " [[[2023, 1072], [2061, 1072], [2061, 1103], [2023, 1103]], '78'],\n",
       " [[[2290, 1072], [2364, 1072], [2364, 1103], [2290, 1103]], '57.5'],\n",
       " [[[2476, 1072], [2548, 1072], [2548, 1103], [2476, 1103]], '49 .8'],\n",
       " [[[2694, 1072], [2765, 1072], [2765, 1103], [2694, 1103]], '60.6'],\n",
       " [[[2928, 1072], [2983, 1072], [2983, 1103], [2928, 1103]], '852'],\n",
       " [[[110, 1151], [129, 1151], [129, 1177], [110, 1177]], '2'],\n",
       " [[[261, 1147], [469, 1147], [469, 1178], [261, 1178]], 'InternVL2-8B'],\n",
       " [[[864, 1147], [1105, 1147], [1105, 1178], [864, 1178]], 'InternLM2.5-7B'],\n",
       " [[[1216, 1143], [1462, 1143], [1462, 1181], [1216, 1181]], 'InternVit-3O0M'],\n",
       " [[[1568, 1147], [1642, 1147], [1642, 1178], [1568, 1178]], '64.1'],\n",
       " [[[1805, 1147], [1843, 1147], [1843, 1178], [1805, 1178]], '15'],\n",
       " [[[2023, 1147], [2095, 1147], [2095, 1178], [2023, 1178]], '79.4'],\n",
       " [[[2290, 1147], [2364, 1147], [2364, 1178], [2290, 1178]], '61.5'],\n",
       " [[[2473, 1147], [2548, 1147], [2548, 1178], [2473, 1178]], '51.2'],\n",
       " [[[2694, 1147], [2765, 1147], [2765, 1178], [2694, 1178]], '58.3'],\n",
       " [[[2928, 1147], [2983, 1147], [2983, 1175], [2928, 1175]], '794'],\n",
       " [[[110, 1223], [129, 1223], [129, 1249], [110, 1249]], '5'],\n",
       " [[[261, 1220], [469, 1220], [469, 1250], [261, 1250]], 'InternVL2-4B'],\n",
       " [[[866, 1220], [955, 1220], [955, 1250], [866, 1250]], 'Phi-3'],\n",
       " [[[1217, 1220], [1459, 1220], [1459, 1250], [1217, 1250]], 'InternVit-300M'],\n",
       " [[[1568, 1220], [1642, 1220], [1642, 1250], [1568, 1250]], '60.6'],\n",
       " [[[1805, 1222], [1880, 1222], [1880, 1250], [1805, 1250]], '25.5'],\n",
       " [[[2023, 1222], [2095, 1222], [2095, 1250], [2023, 1250]], '73.6'],\n",
       " [[[2292, 1222], [2363, 1222], [2363, 1250], [2292, 1250]], '53 _ 9'],\n",
       " [[[2476, 1222], [2548, 1222], [2548, 1250], [2476, 1250]], '48.3'],\n",
       " [[[2694, 1220], [2765, 1220], [2765, 1250], [2694, 1250]], '58.1'],\n",
       " [[[2928, 1220], [2983, 1220], [2983, 1250], [2928, 1250]], '784'],\n",
       " [[[106, 1295], [144, 1295], [144, 1325], [106, 1325]], '13'],\n",
       " [[[261, 1295], [469, 1295], [469, 1325], [261, 1325]], 'InternVL2-2B'],\n",
       " [[[629, 1295], [653, 1295], [653, 1325], [629, 1325]], '2'],\n",
       " [[[864, 1295], [1105, 1295], [1105, 1325], [864, 1325]], 'InternLM2-1.8B'],\n",
       " [[[1217, 1295], [1459, 1295], [1459, 1325], [1217, 1325]], 'InternVit-300M'],\n",
       " [[[1568, 1295], [1609, 1295], [1609, 1325], [1568, 1325]], '54'],\n",
       " [[[1805, 1295], [1880, 1295], [1880, 1325], [1805, 1325]], '49.5'],\n",
       " [[[2023, 1295], [2095, 1295], [2095, 1325], [2023, 1325]], '69.6'],\n",
       " [[[2292, 1295], [2363, 1295], [2363, 1325], [2292, 1325]], '49 _ 8'],\n",
       " [[[2473, 1295], [2548, 1295], [2548, 1325], [2473, 1325]], '36.3'],\n",
       " [[[2694, 1295], [2732, 1295], [2732, 1325], [2694, 1325]], '46'],\n",
       " [[[2928, 1295], [2981, 1295], [2981, 1325], [2928, 1325]], '781'],\n",
       " [[[110, 1373], [129, 1373], [129, 1397], [110, 1397]], '6'],\n",
       " [[[261, 1370], [418, 1370], [418, 1398], [261, 1398]], 'GLM-4v-9B'],\n",
       " [[[633, 1373], [649, 1373], [649, 1397], [633, 1397]], '9'],\n",
       " [[[864, 1370], [1004, 1370], [1004, 1398], [864, 1398]], 'GLM-4-9B'],\n",
       " [[[1217, 1370], [1374, 1370], [1374, 1398], [1217, 1398]], 'EVA-02-5B'],\n",
       " [[[1568, 1370], [1641, 1370], [1641, 1398], [1568, 1398]], '59 1'],\n",
       " [[[1805, 1370], [1894, 1370], [1894, 1398], [1805, 1398]], '31.75'],\n",
       " [[[2023, 1370], [2095, 1370], [2095, 1398], [2023, 1398]], '67.9'],\n",
       " [[[2290, 1370], [2364, 1370], [2364, 1398], [2290, 1398]], '54.8'],\n",
       " [[[2476, 1370], [2548, 1370], [2548, 1398], [2476, 1398]], '46.9'],\n",
       " [[[2694, 1370], [2765, 1370], [2765, 1398], [2694, 1398]], '51.1'],\n",
       " [[[2928, 1370], [2983, 1370], [2983, 1398], [2928, 1398]], '776'],\n",
       " [[[106, 1442], [147, 1442], [147, 1473], [106, 1473]], '26'],\n",
       " [[[261, 1442], [469, 1442], [469, 1473], [261, 1473]], 'InternVL2-1B'],\n",
       " [[[633, 1448], [652, 1448], [652, 1472], [633, 1472]], '1'],\n",
       " [[[864, 1442], [1040, 1442], [1040, 1475], [864, 1475]], 'Qwen2-0 .SB'],\n",
       " [[[1217, 1442], [1459, 1442], [1459, 1473], [1217, 1473]], 'InternVit-3O0M'],\n",
       " [[[1568, 1442], [1642, 1442], [1642, 1473], [1568, 1473]], '48 .3'],\n",
       " [[[1805, 1442], [1894, 1442], [1894, 1473], [1805, 1473]], '69.38'],\n",
       " [[[2023, 1442], [2095, 1442], [2095, 1473], [2023, 1473]], '59.7'],\n",
       " [[[2292, 1445], [2364, 1445], [2364, 1473], [2292, 1473]], '45.6'],\n",
       " [[[2473, 1442], [2548, 1442], [2548, 1473], [2473, 1473]], '36.7'],\n",
       " [[[2694, 1442], [2765, 1442], [2765, 1473], [2694, 1473]], '39.4'],\n",
       " [[[2928, 1442], [2983, 1442], [2983, 1473], [2928, 1473]], '755'],\n",
       " [[[110, 1521], [129, 1521], [129, 1545], [110, 1545]], '3'],\n",
       " [[[260, 1512], [553, 1512], [553, 1551], [260, 1551]], 'Ovisl.5-Llama3-8B'],\n",
       " [[[633, 1521], [652, 1521], [652, 1545], [633, 1545]], '8'],\n",
       " [[[866, 1509], [1410, 1509], [1410, 1557], [866, 1557]],\n",
       "  'Llama-3-8B-Instruct SigLIP-4OOM'],\n",
       " [[[1568, 1517], [1642, 1517], [1642, 1548], [1568, 1548]], '62.2'],\n",
       " [[[1805, 1517], [1843, 1517], [1843, 1548], [1805, 1548]], '20'],\n",
       " [[[2023, 1517], [2095, 1517], [2095, 1548], [2023, 1548]], '76.6'],\n",
       " [[[2292, 1517], [2364, 1517], [2364, 1548], [2292, 1548]], '57.3'],\n",
       " [[[2476, 1517], [2548, 1517], [2548, 1546], [2476, 1546]], '48.3'],\n",
       " [[[2694, 1517], [2732, 1517], [2732, 1546], [2694, 1546]], '63'],\n",
       " [[[2928, 1517], [2983, 1517], [2983, 1546], [2928, 1546]], '744'],\n",
       " [[[110, 1596], [126, 1596], [126, 1617], [110, 1617]], '7'],\n",
       " [[[261, 1590], [585, 1590], [585, 1623], [261, 1623]], 'MiniCPM-Llama3-V2.5'],\n",
       " [[[633, 1596], [649, 1596], [649, 1620], [633, 1620]], '8'],\n",
       " [[[866, 1589], [1409, 1589], [1409, 1627], [866, 1627]],\n",
       "  'Llama-3-8B-Instruct SigLIP-4OOM'],\n",
       " [[[1568, 1590], [1642, 1590], [1642, 1621], [1568, 1621]], '58 . 8'],\n",
       " [[[1805, 1590], [1843, 1590], [1843, 1621], [1805, 1621]], '30'],\n",
       " [[[2023, 1590], [2061, 1590], [2061, 1621], [2023, 1621]], '72'],\n",
       " [[[2290, 1590], [2364, 1590], [2364, 1621], [2290, 1621]], '51.8'],\n",
       " [[[2476, 1592], [2548, 1592], [2548, 1621], [2476, 1621]], '45.8'],\n",
       " [[[2694, 1590], [2765, 1590], [2765, 1621], [2694, 1621]], '54.3'],\n",
       " [[[2928, 1590], [2983, 1590], [2983, 1621], [2928, 1621]], '725'],\n",
       " [[[112, 1671], [129, 1671], [129, 1692], [112, 1692]], '4'],\n",
       " [[[261, 1665], [649, 1665], [649, 1698], [261, 1698]],\n",
       "  'InternLM-XComposer2.5 8'],\n",
       " [[[864, 1665], [1071, 1665], [1071, 1696], [864, 1696]], 'InternLM2-7B'],\n",
       " [[[1217, 1663], [1439, 1663], [1439, 1696], [1217, 1696]], 'CLIP Vit-L/14'],\n",
       " [[[1568, 1665], [1640, 1665], [1640, 1696], [1568, 1696]], '61.1'],\n",
       " [[[1805, 1665], [1897, 1665], [1897, 1698], [1805, 1698]], '23.25'],\n",
       " [[[2023, 1665], [2095, 1665], [2095, 1696], [2023, 1696]], '79.4'],\n",
       " [[[2292, 1665], [2364, 1665], [2364, 1696], [2292, 1696]], '59.9'],\n",
       " [[[2473, 1665], [2548, 1665], [2548, 1696], [2473, 1696]], '42.9'],\n",
       " [[[2694, 1665], [2765, 1665], [2765, 1696], [2694, 1696]], '63.7'],\n",
       " [[[2928, 1665], [2983, 1665], [2983, 1696], [2928, 1696]], '686'],\n",
       " [[[106, 1740], [130, 1740], [130, 1768], [106, 1768]], '8'],\n",
       " [[[260, 1737], [649, 1737], [649, 1774], [260, 1774]],\n",
       "  'InternLM-XComposer2-4 7'],\n",
       " [[[864, 1738], [1071, 1738], [1071, 1768], [864, 1768]], 'InternLM2-7B'],\n",
       " [[[1217, 1738], [1442, 1738], [1442, 1771], [1217, 1771]], 'CLIP Vit-L/14'],\n",
       " [[[1568, 1738], [1642, 1738], [1642, 1768], [1568, 1768]], '58.8'],\n",
       " [[[1805, 1738], [1894, 1738], [1894, 1768], [1805, 1768]], '31.12'],\n",
       " [[[2023, 1738], [2097, 1738], [2097, 1768], [2023, 1768]], '76.5'],\n",
       " [[[2292, 1738], [2364, 1738], [2364, 1768], [2292, 1768]], '55.3'],\n",
       " [[[2473, 1738], [2548, 1738], [2548, 1768], [2473, 1768]], '39.7'],\n",
       " [[[2694, 1738], [2765, 1738], [2765, 1768], [2694, 1768]], '59.4'],\n",
       " [[[2928, 1738], [2983, 1738], [2983, 1768], [2928, 1768]], '675'],\n",
       " [[[106, 1813], [144, 1813], [144, 1843], [106, 1843]], '21'],\n",
       " [[[261, 1813], [649, 1813], [649, 1843], [261, 1843]],\n",
       "  'Mini-InternVL-Chat-2B 2'],\n",
       " [[[864, 1813], [1105, 1813], [1105, 1843], [864, 1843]], 'InternLM2-1.8B'],\n",
       " [[[1217, 1813], [1459, 1813], [1459, 1843], [1217, 1843]], 'InternVit-300M'],\n",
       " [[[1568, 1813], [1642, 1813], [1642, 1843], [1568, 1843]], '49.8'],\n",
       " [[[1805, 1813], [1843, 1813], [1843, 1843], [1805, 1843]], '61'],\n",
       " [[[2023, 1813], [2095, 1813], [2095, 1843], [2023, 1843]], '65.2'],\n",
       " [[[2292, 1813], [2364, 1813], [2364, 1843], [2292, 1843]], '46.7'],\n",
       " [[[2473, 1813], [2548, 1813], [2548, 1843], [2473, 1843]], '37.4'],\n",
       " [[[2694, 1813], [2765, 1813], [2765, 1843], [2694, 1843]], '41.3'],\n",
       " [[[2928, 1813], [2983, 1813], [2983, 1843], [2928, 1843]], '652'],\n",
       " [[[106, 1888], [144, 1888], [144, 1916], [106, 1916]], '12'],\n",
       " [[[261, 1885], [649, 1885], [649, 1918], [261, 1918]],\n",
       "  'Mini-InternVL-Chat-4B 4'],\n",
       " [[[866, 1885], [955, 1885], [955, 1916], [866, 1916]], 'Phi-3'],\n",
       " [[[1217, 1885], [1459, 1885], [1459, 1918], [1217, 1918]], 'InternVit-3OOM'],\n",
       " [[[1568, 1885], [1642, 1885], [1642, 1916], [1568, 1916]], '56.2'],\n",
       " [[[1805, 1888], [1894, 1888], [1894, 1916], [1805, 1916]], '37.25'],\n",
       " [[[2023, 1888], [2095, 1888], [2095, 1916], [2023, 1916]], '69.7'],\n",
       " [[[2292, 1888], [2363, 1888], [2363, 1916], [2292, 1916]], '53 _ 1'],\n",
       " [[[2476, 1888], [2548, 1888], [2548, 1916], [2476, 1916]], '45.1'],\n",
       " [[[2694, 1888], [2765, 1888], [2765, 1916], [2694, 1916]], '54.6'],\n",
       " [[[2928, 1888], [2983, 1888], [2983, 1916], [2928, 1916]], '639'],\n",
       " [[[265, 1964], [313, 1964], [313, 1978], [265, 1978]], 'NL:'],\n",
       " [[[362, 1961], [397, 1961], [397, 1978], [362, 1978]], ':'],\n",
       " [[[867, 1964], [915, 1964], [915, 1978], [867, 1978]], 'NL:'],\n",
       " [[[1222, 1965], [1244, 1965], [1244, 1974], [1222, 1974]], 'A'],\n",
       " [[[1255, 1961], [1358, 1961], [1358, 1978], [1255, 1978]], 'Tn Wt'],\n",
       " [[[1393, 1961], [1421, 1961], [1421, 1978], [1393, 1978]], '1^'],\n",
       " [[[1574, 1964], [1608, 1964], [1608, 1978], [1574, 1978]], 'Co'],\n",
       " [[[1811, 1964], [1842, 1964], [1842, 1978], [1811, 1978]], 'Ar'],\n",
       " [[[1857, 1964], [1891, 1964], [1891, 1978], [1857, 1978]], 'Nr'],\n",
       " [[[2298, 1964], [2329, 1964], [2329, 1978], [2298, 1978]], '4N'],\n",
       " [[[87, 2055], [185, 2055], [185, 2085], [87, 2085]], 'Citation'],\n",
       " [[[1305, 2150], [1439, 2150], [1439, 2183], [1305, 2183]], 'Use via API'],\n",
       " [[[1520, 2152], [1722, 2152], [1722, 2182], [1520, 2182]],\n",
       "  'Built with Gradio']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(\"images/evals.png\",paragraph=\"False\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class ChatMessage(BaseModel):\n",
    "    sender: str\n",
    "    message: str\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    person_we_are_corresponding_to: str\n",
    "    messages: list[ChatMessage]\n",
    "\n",
    "class GeneralistReasoning(BaseModel):\n",
    "    source: str\n",
    "    summary: str\n",
    "    details: str\n",
    "\n",
    "client = OpenAI()\n",
    "class GPTModel:\n",
    "    def __init__(self):\n",
    "        # self.model = \"gpt-4o-mini-2024-07-18\"\n",
    "        self.model = \"gpt-4o-2024-08-06\"\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    # Function to encode the image\n",
    "    def encode_image(self, image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        \n",
    "    def format_inputs_to_message(self, image, prompt):\n",
    "        formatted_image = image if image.startswith(\"http\") else f\"data:image/jpeg;base64,{self.encode_image(image)}\"\n",
    "        image_dict = {\"url\": formatted_image}\n",
    "        prompt_dict = {\"type\": \"text\", \"text\": prompt}\n",
    "        image_dict = {\"type\": \"image_url\", \"image_url\": image_dict}\n",
    "        user_content = [prompt_dict, image_dict]\n",
    "        messages = [{\"role\": \"user\", \"content\": user_content}]\n",
    "        return messages\n",
    "    \n",
    "    def forward(self, image, prompt):\n",
    "        messages = self.format_inputs_to_message(image, prompt)\n",
    "        response = self.client.beta.chat.completions.parse(model=self.model, messages=messages)\n",
    "        return response.choices[0]\n",
    "\n",
    "from prompting import generalist_prompt, conversation_prompt\n",
    "class GeneralistModel(GPTModel):\n",
    "    def forward(self, image):\n",
    "        messages = self.format_inputs_to_message(image, generalist_prompt)\n",
    "        response = self.client.beta.chat.completions.parse(model=self.model, response_format=GeneralistReasoning, messages=messages)\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "class ConversationModel(GPTModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "    def forward(self, image):\n",
    "        messages = self.format_inputs_to_message(image, conversation_prompt)\n",
    "        response = self.client.beta.chat.completions.parse(model=self.model, response_format=Conversation, messages=messages, temperature=0.2)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_agent = GeneralistModel()\n",
    "conversation_agent = ConversationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"person_we_are_corresponding_to\":\"+1 (510) 542-0847\",\"messages\":[{\"sender\":\"Me\",\"message\":\"Kamal congrats on YC dude! Hope you’re doing good :)\"},{\"sender\":\"+1 (510) 542-0847\",\"message\":\"Thank you Mehmet !\"},{\"sender\":\"+1 (510) 542-0847\",\"message\":\"Sorry for missing this\"},{\"sender\":\"+1 (510) 542-0847\",\"message\":\"Just launched :)\"}]}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_agent.forward(\"images/image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Google Calendar',\n",
       " 'summary': 'Calendar events for September 7th, 2024',\n",
       " 'details': \"Event 1: 'Cari!' | Date: 2024-09-07 | Start: 4:00 AM | End: 6:00 AM\\nEvent 2: 'Weekly Reflection' | Date: 2024-09-07 | Start: 4:00 AM | End: 4:45 AM\\nEvent 3: 'Yamasun' | Date: 2024-09-07 | Start: 8:00 AM | End: 12:00 PM\\nEvent 4: 'AI Goes Local' | Date: 2024-09-07 | Start: 11:00 AM | End: 8:00 PM\\nEvent 5: 'Calvin' | Date: 2024-09-07 | Start: 3:30 PM | End: 4:30 PM | Location: 1630 Mission St\\nEvent 6: 'SF Startup Series' | Date: 2024-09-07 | Start: 5:00 PM | Location: 414 Oak St\\nEvent 7: 'Arya' | Date: 2024-09-07 | Start: 7:00 PM | End: 8:00 PM\\nEvent 8: 'Housewarming Dinner' | Date: 2024-09-07 | Start: 7:30 PM | End: 9:30 PM\\nEvent 9: 'Elf = Deniz' | Date: 2024-09-09 | 8:00 AM - 8:45 AM\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = general_agent.forward(\"images/calendar.png\")\n",
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Dashboard - Model Evaluation Results',\n",
       " 'summary': 'Tabular data of model evaluation results',\n",
       " 'details': \"Header: 'Rank', 'Method', 'Param (B)', 'Language Model', 'Vision Model', 'Avg Score', 'Avg Rank', 'MMBench_V11', 'MMStar', 'MMMU_VAL', 'MathVista', 'OCR'\\nRow 1: '1', 'MiniCPM-V-2.6', '8', 'Qwen2-7B', 'SigLIP-400M', '65.2', '13.62', '78', '57.5', '49.8', '60.6', '852'\\nRow 2: '2', 'InternVL-2-8B', '8', 'InternLM2.5-7B', 'InternViT-300M', '64.1', '15', '79.4', '61.5', '51.2', '58.3', '794'\\nRow 3: '3', 'InternVL-2-4B', '4', 'Phi-3', 'InternViT-300M', '60.6', '25.5', '73.6', '53.9', '48.3', '58.1', '784'\\nRow 4: '4', 'InternVL-2-2B', '2', 'InternLM2-1.8B', 'InternViT-300M', '54', '49.5', '69.6', '49.8', '36.3', '46', '781'\\nRow 5: '5', 'GLM-4v-9B', '9', 'GLM-4-9B', 'EVA-02-5B', '59.1', '31.75', '67.9', '54.8', '46.9', '51.1', '776'\\nRow 6: '26', 'InternVL-1B', '1', 'Qwen2-0.5B', '', '48.3', '', '59.7', '45.6', '36.7', '', '755'\\nRow 7: '7', 'Ovisi.5-Llama3-8B', '8', 'Llama-3-8B-Instruct', 'SigLIP-400M', '62.2', '20', '76.6', '57.7', '48.3', '63', '744'\\nRow 8: '8', 'MiniCPM-Llama3-V2.5', '8', 'Llama-3-8B-Instruct', 'SigLIP-400M', '60.1', '30', '72', '51.8', '54.3', '725'\\nRow 9: '21', 'Mini-InternVL-Chat-2B', '2', 'InternLM2-7B', 'CLIP ViT-L/14', '23.25', '79.4', '49.2', '42.9', '63.7', '686'\\nRow 10: '17', 'InternLM-XComposer2.5', '8', 'InternLM2-7B', 'CLIP ViT-L/14', '31.12', '76.5', '55.3', '39.7', '59.4', '675'\\nRow 11: '22', 'Mini-InternVL-Chat-4B', '4', 'Phi-3', 'InternViT-300M', '37.25', '69.7', '53.1', '45.1', '54.6', '639'\\nRow 12: '16', '', '0', '', '', '37.5', '66.5', '58.6', '43', '36.3', '633'\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = general_agent.forward(\"images/evals.png\")\n",
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: 'Rank', 'Method', 'Param (B)', 'Language Model', 'Vision Model', 'Avg Score', 'Avg Rank', 'MMBench_V11', 'MMStar', 'MMMU_VAL', 'MathVista', 'OCR'\n",
      "Row 1: '1', 'MiniCPM-V-2.6', '8', 'Qwen2-7B', 'SigLIP-400M', '65.2', '13.62', '78', '57.5', '49.8', '60.6', '852'\n",
      "Row 2: '2', 'InternVL-2-8B', '8', 'InternLM2.5-7B', 'InternViT-300M', '64.1', '15', '79.4', '61.5', '51.2', '58.3', '794'\n",
      "Row 3: '3', 'InternVL-2-4B', '4', 'Phi-3', 'InternViT-300M', '60.6', '25.5', '73.6', '53.9', '48.3', '58.1', '784'\n",
      "Row 4: '4', 'InternVL-2-2B', '2', 'InternLM2-1.8B', 'InternViT-300M', '54', '49.5', '69.6', '49.8', '36.3', '46', '781'\n",
      "Row 5: '5', 'GLM-4v-9B', '9', 'GLM-4-9B', 'EVA-02-5B', '59.1', '31.75', '67.9', '54.8', '46.9', '51.1', '776'\n",
      "Row 6: '26', 'InternVL-1B', '1', 'Qwen2-0.5B', '', '48.3', '', '59.7', '45.6', '36.7', '', '755'\n",
      "Row 7: '7', 'Ovisi.5-Llama3-8B', '8', 'Llama-3-8B-Instruct', 'SigLIP-400M', '62.2', '20', '76.6', '57.7', '48.3', '63', '744'\n",
      "Row 8: '8', 'MiniCPM-Llama3-V2.5', '8', 'Llama-3-8B-Instruct', 'SigLIP-400M', '60.1', '30', '72', '51.8', '54.3', '725'\n",
      "Row 9: '21', 'Mini-InternVL-Chat-2B', '2', 'InternLM2-7B', 'CLIP ViT-L/14', '23.25', '79.4', '49.2', '42.9', '63.7', '686'\n",
      "Row 10: '17', 'InternLM-XComposer2.5', '8', 'InternLM2-7B', 'CLIP ViT-L/14', '31.12', '76.5', '55.3', '39.7', '59.4', '675'\n",
      "Row 11: '22', 'Mini-InternVL-Chat-4B', '4', 'Phi-3', 'InternViT-300M', '37.25', '69.7', '53.1', '45.1', '54.6', '639'\n",
      "Row 12: '16', '', '0', '', '', '37.5', '66.5', '58.6', '43', '36.3', '633'\n"
     ]
    }
   ],
   "source": [
    "print(_43[\"details\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Google Calendar', 'summary': 'Calendar events for September 7-10, 2024', 'details': \"Event 1: Can't Siglo? RushNampa Inka Ei | Date: 2024-09-07 | Start: 8:00 AM | End: 9:00 AM\\nEvent 2: Weekly Reflection | Date: 2024-09-07 | Start: 4:45 PM | End: 5:00 PM\\nEvent 3: AI Goes Local | Date: 2024-09-07 | Start: 11:00 AM | End: 6:00 PM\\nEvent 4: Yarmasun | Date: 2024-09-08 | Start: 8:00 AM | End: 12:00 PM\\nEvent 5: Calvin | Date: 2024-09-08 | Start: 2:30 PM | End: 4:30 PM\\nEvent 6: SF Startup Series | Date: 2024-09-08 | Start: 5:00 PM | End: 6:00 PM\\nEvent 7: Aya | Date: 2024-09-08 | Start: 7:00 PM | End: 8:00 PM\\nEvent 8: Elf = Deniz | Date: 2024-09-09 | Start: 8:45 AM | End: 9:00 AM\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = general_agent.forward(\"images/calendar.png\")\n",
    "print(json.loads(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Web Application - Model Evaluation Results', 'summary': 'Main evaluation results for AI models', 'details': \"Header: 'Rank', 'Method', 'Params (B)', 'Language Model', 'Vision Model', 'Avg Score', 'Avg Rank', 'MMBench_V11', 'MMStar', 'MMMU_VAL', 'MathVista', 'OCR'\\nRow 1: '1', 'MiniCPM-V2.6', '8', 'Qwen2-7B', 'SigILIP-400M', '65.2', '13.62', '78', '57.5', '49.8', '60.6', '852'\\nRow 2: '2', 'InternVL-2-8B', '8', 'InternLM2.5-7B', 'InternViT-300M', '64.1', '15', '79.4', '61.5', '51.2', '58.3', '794'\\nRow 3: '3', 'InternVL-2-4B', '4', 'Phi-3', 'InternViT-300M', '60.6', '25.5', '73.6', '53.9', '48.3', '58.1', '784'\\nRow 4: '4', 'InternVL-2-2B', '2', 'InternLM2-1.8B', 'InternViT-300M', '54', '49.5', '69.6', '49.8', '36.3', '46', '781'\\nRow 5: '5', 'GLM-4v-9B', '9', 'GLM-4.9', 'EVA-02-5B', '59.1', '31.75', '67.9', '54.8', '46.9', '51.1', '776'\\nRow 6: '26', 'InternVL-1B', '', 'Qwen2-0.5B', '', '48.3', '69.38', '59.7', '45.6', '36.7', '39.4', '755'\\nRow 7: '13', 'Ovisi.5-Llama3-8B', '8', 'Llama-3-8B-Instruct', 'SigILIP-400M', '62.2', '20', '76.6', '57.3', '48.3', '63', '744'.\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = general_agent.forward(\"images/evals.png\")\n",
    "print(json.loads(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: 'Rank', 'Method', 'Param (B)', 'Language Model', 'Vision Model', 'Avg Score', 'Avg Rank', 'MMBench_V11', 'MMStar', 'MMMU_VAL', 'MathVista', 'OCR'\n",
      "Row 1: '1', 'MiniCPM-V-2.6', '8', 'Qwen2-7B', 'SigLIP-400M', '65.2', '13.62', '78', '57.5', '49.8', '60.6', '852'\n",
      "Row 2: '5', 'InternLMv2-8B', '8', 'InternLM2.5-7B', 'InternViT-300M', '64.1', '15', '79.4', '61.5', '51.2', '58.3', '794'\n",
      "Row 3: '5', 'InternLV2-4B', '4', 'Phi-3', 'InternViT-300M', '60.6', '25.5', '73.6', '53.9', '48.3', '58.1', '784'\n",
      "Row 4: '13', 'InternLV2-2B', '2', 'InternLM2-1.8B', 'InternViT-300M', '54', '49.5', '69.6', '49.8', '36.3', '46', '781'\n",
      "Row 5: '6', 'GLM-4v-9B', '9', 'GLM-4-9B', 'EVA-02-5B', '59.1', '31.75', '67.9', '54.8', '46.9', '51.1', '776'\n",
      "Row 6: '26', 'InternLVL2-1B', '1', 'Qwen2-0.5B', 'InternViT-300M', '48.3', '50.9', '59.7', '45.6', '36.7', '39.4', '755'\n",
      "Row 7: '3', 'Ovisi_5-llama3-8B', '8', 'Llama-3-8B-Instruct', 'SigLIP-400M', '62.2', '20', '76.6', '57.3', '48.3', '63', '744'\n",
      "Row 9: '7', 'MiniCPM-Llama3-V2.5', '8', 'Llama-3-8B-Instruct', 'SigLIP-400M', '58.8', '30', '72', '51.8', '45.8', '54.3', '725'\n",
      "Row 10: '4', 'InternLM-XComposer2.5', '8', 'InternLM2-7B', 'CLIP ViT-L/14', '59.3', '23.25', '79.4', '59.9', '42.9', '63.7', '686'\n",
      "Row 14: '8', 'InternLM-XComposer2-4', '7', 'InternLM2-7B', 'CLIP ViT-L/14', '58.83', '31.12', '76.5', '55.3', '39.7', '59.4', '675'\n",
      "Row 15: '21', 'Mini-InternVL-Chat-2B-2', '2', 'InternLM2-1.8B', 'InternViT-300M', '56.2', '61', '65.2', '46.7', '37.4', '41.3', '652'\n",
      "Row 16: '12', 'Mini-InternVL-Chat-4B-4', '4', 'Phi-3', 'InternViT-300M', '56.2', '37.25', '69.7', '53.1', '45.1', '54.6', '639'\n",
      "Row 17: '28', 'Dbp-2-Wisdom', '2', 'InternLM2-1.8B', 'InternViT-300M', '47.2', '43.75', '54.6', '48.8', '37.2', '40.9', '636'\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(response)[\"details\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the events from your calendar for September 7th to September 10th, 2024:\n",
      "\n",
      "### Saturday, September 7th, 2024\n",
      "- **Event:** Can’t Stop! (Rush/Mmmpie Knar En)\n",
      "  - **Start Time:** 1 AM\n",
      "  - **End Time:** 2 AM\n",
      "  \n",
      "- **Event:** Weekly Reflection\n",
      "  - **Start Time:** 4 AM\n",
      "  - **End Time:** 4:45 AM\n",
      "\n",
      "### Sunday, September 8th, 2024\n",
      "There are no events on this day.\n",
      "\n",
      "### Monday, September 9th, 2024\n",
      "- **Event:** Yamusan\n",
      "  - **Start Time:** 8 AM\n",
      "  - **End Time:** 12 PM\n",
      "  \n",
      "- **Event:** AI Goes Local\n",
      "  - **Start Time:** 11 AM\n",
      "  - **End Time:** 8 PM\n",
      "\n",
      "- **Event:** Calvin\n",
      "  - **Start Time:** 3:30 PM\n",
      "  - **End Time:** 4:30 PM\n",
      "  - **Location:** 1600 Mission St\n",
      "\n",
      "- **Event:** SF Startup Series\n",
      "  - **Start Time:** 5 PM\n",
      "  - **End Time:** 6 PM\n",
      "  - **Location:** 441 Oak St\n",
      "\n",
      "- **Event:** Arya\n",
      "  - **Start Time:** 7 PM\n",
      "  - **End Time:** 8 PM\n",
      "\n",
      "- **Event:** Housewarming Dinner\n",
      "  - **Start Time:** 7:30 PM\n",
      "  - **End Time:** 9:30 PM\n",
      "\n",
      "### Tuesday, September 10th, 2024\n",
      "- **Event:** Eif w/ Deniz\n",
      "  - **Start Time:** 8 AM\n",
      "  - **End Time:** 8:45 AM\n"
     ]
    }
   ],
   "source": [
    "print(gpt.forward(\"images/calendar.png\", \"Look at my calendar and output all the events that I have, when they start, and when they end.\").message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Main Evaluation Results\n",
      "\n",
      "### Metrics:\n",
      "- **Avg Score:** The average score on all VLM Benchmarks (normalized to 0 - 100, the higher the better).\n",
      "- **Avg Rank:** The average rank on all VLM Benchmarks (the lower the better).\n",
      "- **Avg Score & Rank** are calculated based on the selected benchmark. When results for some selected benchmarks are missing, Avg Score / Rank will be None.\n",
      "- By default, the overall evaluation results are based on 8 VLM benchmarks, sorted by the descending order of Avg Score.\n",
      "  - The following datasets are included in the main results: MMBench_V11, MMStar, MMMU_VAL, MathVista, OCRBench, AID2, HallusionBench, MMVet.\n",
      "  - Detailed evaluation results for each dataset (included or not included in main) are provided in the consequent tabs.\n",
      "\n",
      "### Evaluation Dimension\n",
      "\n",
      "| Avg Score | Avg Rank | MMBench_V11 | MMStar | MME | MMMU_VAL | MathVista | OCRBench | AID2 | HallusionBench | SEEDBench_IMG | LLaVA-Bench | CCBench | RealWorldQA | POPE | ScienceQA_TEST | SEEDBench2_Plus | MMT-Bench_VAL | BLINK |\n",
      "\n",
      "### Model Size:\n",
      "- <4B\n",
      "- 4B-10B\n",
      "- 10B-20B\n",
      "- 20B-40B\n",
      "- >40B\n",
      "- Unknown\n",
      "\n",
      "### Model Type:\n",
      "- API\n",
      "- OpenSource\n",
      "- Proprietary\n",
      "\n",
      "### Table of Results\n",
      "\n",
      "| Rank | Method                    | Param (B) | Language Model    | Vision Model         | Avg Score | Avg Rank | MMBench_V11 | MMStar | MMMU_VAL | MathVista | OCR |\n",
      "|------|---------------------------|-----------|--------------------|----------------------|-----------|----------|-------------|--------|-----------|------------|-----|\n",
      "| 1    | MiniCPM-V-2.6             | 8         | Qwen2-7B           | SigLIP-400M          | 65.2      | 13.62    | 78          | 57.5   | 49.8      | 60.6       | 852 |\n",
      "| 2    | InternVL2-8B              | 8         | InternLM2-5.7B     | InternViT-300M       | 64.1      | 15       | 79.4        | 61.5   | 51.2      | 58.3       | 794 |\n",
      "| 5    | InternVL2-4B              | 4         | Phi-3              | InternViT-300M       | 60.6      | 25.5     | 73.6        | 53.9   | 48.3      | 58.1       | 784 |\n",
      "| 12   | InternVL2-2B              | 2         | InternLM2-1.8B     | InternViT-300M       | 54        | 49.5     | 69.6        | 49.8   | 36.3      | 46         | 781 |\n",
      "| 6    | GLM-4v-9B                 | 9         | GLM-4-9B           | EVA-02-5B            | 59.1      | 31.75    | 67.9        | 54.8   | 46.9      | 51.1       | 776 |\n",
      "| 26   | InternVL2-1B              | 1         | Qwen2-0.5B         | InternViT-300M       | 48.3      | 50       | 59.7        | 45.6   | 36.7      | 39.4       | 755 |\n",
      "| 3    | Ovisi.5-Llama3-8B         | 8         | Llama-3-8B-Instruct| SigLIP-400M          | 62.2      | 20       | 76.6        | 57.7   | 48.3      | 63         | 744 |\n",
      "| 7    | MiniCPM-Llama3-V2.5-8     | 8         | Llama-3-8B-Instruct| SigLIP-400M          | 58.8      | 30       | 72          | 51.8   | 45.8      | 54.3       | 725 |\n",
      "| 4    | InternLM-XComposer2.5-8   | 8         | InternLM2-7B       | CLIP ViT-L/14        | 61        | 23.25    | 79.4        | 59.9   | 42.9      | 63.7       | 686 |\n",
      "| 8    | InternLM-XComposer2-4.7   | 7         | InternLM2-7B       | CLIP ViT-L/14        | 58.3      | 31.12    | 76.5        | 55.3   | 39.7      | 59.4       | 675 |\n",
      "| 21   | Mini-InternVL2-Chat-2B    | 2         | InternLM2-1.8B     | InternViT-300M       | 51.6      | 41       | 65.2        | 49.2   | 46.7      | 41.3       | 652 |\n",
      "| 22   | Mini-InternVL2-Chat-4B    | 4         | Phi-3              | InternViT-300M       | 56.2      | 37.25    | 69.7        | 53.1   | 45.1      | 54.6       | 639 |\n",
      "| 15   | GLM-2-Wisdom              | 6.5       | GLM-6/10B          | InternViT-300M       | 55.8      | 45.72    | 70.2        | 49.2   | 48.6      | 52.1       | 627 |\n",
      "\n",
      "### Notes\n",
      "- **Citation:** Not provided.\n",
      "\n",
      "**Use via API:** Built with Gradio.\n"
     ]
    }
   ],
   "source": [
    "print(gpt.forward(\"images/evals.png\", \"Parse all the information on the string, output in terms of text or a markdown format. Do not truncate information.\").message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screenshot shows a dashboard for visualizing machine learning experiments in a project titled \"**hw2p2**\" within the workspace of a user called \"Denizbirlikci\" on a platform that appears to be Weights & Biases (W&B).\n",
      "\n",
      "Key elements of the screenshot:\n",
      "\n",
      "1. **Warning Banner**: The user has exceeded 100% of their tracking hours and is prompted to upgrade their plan to continue using W&B without interruption.\n",
      "   \n",
      "2. **Project Header**: The project is named \"raj_deniz_josh_simrit,\" and the specific sub-project or notebook in use is \"hw2p2.\"\n",
      "\n",
      "3. **Workspace Overview**: \n",
      "\n",
      "    - The workspace is showing multiple runs (62 total in this example) with a table of the different runs on the left side, each with unique names (e.g., \"raj-rewritten-convnxt,\" \"raj-adam-with-warmup,\" \"deniz:viShNet:AdamW-RETRY\").\n",
      "    - Various icons indicate the status, tags, and other attributes of these runs.\n",
      "\n",
      "4. **Charts/Visualizations**: Six main charts illustrate the results of different runs:\n",
      "   \n",
      "    - **Train Accuracy (train_Acc)**\n",
      "    - **Train Loss (train_loss)**\n",
      "    - **Validation Accuracy (validation_Acc)**\n",
      "    - **Validation Loss (validation_loss)**\n",
      "    - **Learning Rate (learning_Rate)**\n",
      "    - **System Metrics**: GPU Power Usage, GPU Power Usage (%), and GPU Memory Allocated (%)\n",
      "\n",
      "5. **Run Comparisons**: The charts compare various runs using different hyperparameters or experimental setups. Comparison runs are color-coded for clarity.\n",
      "\n",
      "6. **Interface Elements**: Standard interface elements for W&B like the option to add panels or filters, and tabs for Overview, Runs, Sweeps, Reports, Artifacts, etc.\n",
      "\n",
      "At the bottom, there are various applications open on the macOS dock, including iMessage, Mail, Finder, Safari, GitHub Desktop, Terminal, and several others.\n",
      "\n",
      "The dashboard is designed to help users track and visualize the performance of their machine learning experiments over time, making it easier to compare different training configurations and select the optimal one.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You're a helpful assistant to take a screenshot of a UI and explain everything going on in the interface. \n",
    "\n",
    "For this image, explain each graph you see. Write a few details on how runs have formulated. \n",
    "\n",
    "Imagine that you're explaining this to someone that will never see the image.\n",
    "\n",
    "Explain each graph and how each run's performance on each graph looks like. \n",
    "\"\"\"\n",
    "\n",
    "print(gpt.forward(\"images/wandb.png\", \"\").message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt.forward(\"images/calendar.png\", \"Parse all the information on the string, output in terms of text or a markdown format. Do not truncate information.\").message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# Main Evaluation Results\\n\\n## Metrics:\\n- **Avg Score**: The average score on all VLM Benchmarks (normalized to 0 - 100, the higher the better).\\n- **Avg Rank**: The average rank on all VLM Benchmarks (the lower the better).\\n- **Avg Score & Rank** are calculated based on selected benchmark. When results for some selected benchmarks are missing, Avg Score / Rank will be None!!\\n\\nBy default, we present the overall evaluation results based on 8 VLM benchmarks, sorted by the descending order of Avg Score.\\n- The following datasets are included in the main results: MMBench_V11, MMStar, MME, MMU_VAL, MathVista, OCRBench, AID2, HallusionBench, SEEDBench, MMVet.\\n- Detailed evaluation results for each dataset (included or not included in main) are provided in the consequent tabs.\\n\\n## Evaluation Dimension\\n- Avg Score\\n- Avg Rank\\n- MMBench_V11\\n- MMStar\\n- MME\\n- MMU_VAL\\n- MathVista\\n- OCRBench\\n- AID2\\n- HallusionBench\\n- SEEDBench_Plus\\n- MMT-Bench_VAL\\n- BLINK\\n\\n## Model Size\\n- <4B\\n- 4B-10B\\n- 10B-20B\\n- 20B-40B\\n- >40B\\n- Unknown\\n\\n## Rankings\\n| Rank | Method               | Param (B) | Language Model     | Vision Model      | Avg Score | Avg Rank | MMBench_V11 | MMStar | MMU_VAL | MathVista | OCR |\\n|------|----------------------|-----------|---------------------|--------------------|-----------|----------|--------------|--------|---------|-----------|-----|\\n| 1    | MiniCPM-V.2.6       | 8         | Qwen2-7B            | SigLIP-400M        | 65.2      | 13.62    | 78           | 57.5   | 49.8    | 60.6      | 852 |\\n| 2    | InternVL-2-8        | 8         | InternLM2.5-7B      | InternViT-300M     | 64.1      | 15       | 79.4         | 61.5   | 51.2    | 58.3      | 794 |\\n| 3    | InternVL2-4B        | 4         | Phi-3               | InternLM2-3B       | 60.6      | 25.5     | 73.6         | 53.9   | 48.3    | 58.1      | 784 |\\n| 4    | InternVL2-2B        | 2         | InternLM2-1.8B      | InternViT-300M     | 54        | 49.5     | 69.6         | 49.8   | 36.3    | 46       | 781 |\\n| 5    | GLM-4v-9B           | 9         | GLM-4.0             | EVA-02-5B          | 59.1      | 31.75    | 67.9         | 54.8   | 46.9    | 51.1      | 776 |\\n| 6    | InternVL2-1B        | 1         | Qwen2-0.5B          | InternViT-300M     | 48.3      | 69.38    | 59.7         | 45.6   | 36.7    | 39.4      | 755 |\\n| 7    | Ovis1.5-Llama3-8B   | 8         | Llama-3-8B-Insturct | SigLIP-400M        | 62.2      | 20       | 76.6         | 57.3   | 48.3    | 63       | 744 |\\n| 8    | MiniCPM-Llama3-V2.5 | 8         | Llama-3-8B-Insturct | SigLIP-400M        | 62.2      | 30       | 72           | 51.8   | 54.3    | 725       | 725 |\\n| 9    | InternLM-XComposer2.5| 8         | InternLM2-7B        | CLIP ViT-L/14      | 31.12     | 76.5     | 55.3         | 39.7   | 59.4    | 675       | 675 |\\n| 10   | InternLM-XComposer2-4| 7         | InternLM2-7B        | CLIP ViT-L/14      | 31.12     | 76.5     | 65.2         | 46.7   | 37.4    | 41.3      | 652 |\\n| 11   | InternVL-Chat-2     | 2         | InternML-1.8B       | InternViT-300M     | 37.25     | 69.7     | 53.1         | 45.1   | 54.6    | 639       | 639 |\\n| 12   | Mini-InternVL-Chat-4| 4         | Phi-3               | InternViT-300M     | 65.2      | 48.17    | 67.3         | 51.3   | 45.1    | 627       | 627 |\\n\\n## Use via API\\n- Built with Gradio 🦙', refusal=None, role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.forward(\"images/evals.png\", \"Parse all the information on the string, output in terms of text or a markdown format. Do not truncate information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s a parsed representation of the information presented in the image:\n",
      "\n",
      "## Main Evaluation Results\n",
      "\n",
      "### Metrics\n",
      "- **Avg Score**: The average score on all VLM Benchmarks (normalized to 0 - 100, the higher the better).\n",
      "- **Avg Rank**: The average rank on all VLM Benchmarks (the lower the better).\n",
      "- **Avg Score & Rank**: Calculated based on selected benchmarks. If results for some benchmarks are missing, Avg Score/Rank will be `None`.\n",
      "\n",
      "### Evaluation Dimension\n",
      "- The results are organized by descending order of Avg Score.\n",
      "- The following datasets are included:\n",
      "  - MMBench_V11\n",
      "  - MMStar\n",
      "  - MME\n",
      "  - MMU_VAL\n",
      "  - MathVista\n",
      "  - OCRBench\n",
      "  - AID2\n",
      "  - HallusionBench\n",
      "  - SEEDBench_Plus\n",
      "  - MMT-Bench_VAL\n",
      "  - BLINK\n",
      "\n",
      "### Model Size\n",
      "- Options are available for <4B, 4B-10B, 10B-20B, 20B-40B, >40B, Unknown.\n",
      "\n",
      "### Table: Model Performance\n",
      "| Rank | Method               | Params (B) | Language Model     | Vision Model       | Avg Score | Avg Rank | MMBench_V11 | MMStar | MMU_VAL | MathVista | OCR |\n",
      "|------|---------------------|------------|---------------------|---------------------|-----------|----------|-------------|--------|---------|-----------|-----|\n",
      "| 1    | MiniCPM-V.2.6      | 8          | Qwen2-7B            | SigLIP-400M         | 65.2      | 13.62    | 78          | 57.5   | 49.8    | 60.6      | 852 |\n",
      "| 2    | InternVL-2B-8      | 8          | InternLM2-5-7B      | InternViT-300M      | 64.1      | 15       | 79.4        | 61.5   | 51.2    | 58.3      | 794 |\n",
      "| 3    | InternVL-2-4B      | 4          | Phi-3               | InternViT-300M      | 60.6      | 25.5     | 73.6        | 53.9   | 48.3    | 58.1      | 784 |\n",
      "| 4    | InternVL-2-2B      | 2          | InternLM2-1.8B      | InternViT-300M      | 54        | 49.5     | 69.6        | 49.8   | 36.3    | 46       | 781 |\n",
      "| 5    | GLM-4v-9B          | 9          | GLM-4.9             | EVA-02-5B           | 59.1      | 31.75    | 67.9        | 54.8   | 46.9    | 51.1      | 776 |\n",
      "| 26   | InternVL-1B        | -          | Qwen2-0.5B          | -                   | 48.3      | 54.5     | 67.9        | 59.7   | 36.7    | 39.4      | 755 |\n",
      "| ...  | ...                 | ...        | ...                 | ...                 | ...       | ...      | ...         | ...    | ...     | ...       | ... |\n",
      "\n",
      "### Model Type\n",
      "- **API**\n",
      "- **OpenSource**\n",
      "- **Proprietary**\n",
      "\n",
      "### Citation\n",
      "Use via API.  \n",
      "Built with Gradio.\n"
     ]
    }
   ],
   "source": [
    "print(_12.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
